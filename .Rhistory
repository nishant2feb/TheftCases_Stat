install.packages("zoo")
install.packages("MASS")
install.packages("scales")
install.packages("chron")
install.packages("ggplot2")
library(tidyr)
library(dplyr)
library(mclust)
library(lubridate)
library(plyr)
library(imputeTS)
library(reshape2)
library(zoo)
library(MASS)
library(scales)
library(chron)
library(ggplot2)
??Kalman
######################################################################################################
# Import Libraries
######################################################################################################
library(dplyr)
library(tidyr)
library(ggplot2)
# For year mon field
library(zoo)
# For extracting date compnents from Date format
library(lubridate)
# For fomating labels on axis
library(scales)
# Package for Gaussian Mixture Clustering
require(mclust)
# For time variables
require(chron)
# For loading BIRCH Clustering
library(MASS)
######################################################################################################
# Function for computing Average Consumption Per day from consumption data
######################################################################################################
getPerDayConsumption <- function(df){
# compute the unique df
#df = unique(df)
df = transform(df,
MonthofConsumption = as.Date(MonthofConsumption, '%Y-%m-%d'),
ConsumptionFrom = as.Date(ConsumptionFrom,'%Y-%m-%d'),
ConsumptionTo = as.Date(ConsumptionTo,'%Y-%m-%d'),
RateCategory = as.factor(RateCategory))
# Load library plyr
library(plyr)
groupColumns = c("ConsumerNumber","ConsumptionFrom","ConsumptionTo")
dataColumns = c("ISU_Consumption_KVAH","ISU_Consumption_KWH","Consumption_TOD1",
"Consumption_TOD2","Consumption_TOD3")
# Aggregate over Consumption
temp2 = ddply(df, groupColumns, function(x) colSums(x[dataColumns]))
# Aggregate over Demand
groupColumns = c("ConsumerNumber","ConsumptionFrom","ConsumptionTo","UOM")
dataColumns = c("BillableDemandConsumption","PenalDemand","RecordedDemand")
temp2 = transform(temp2, ConsumptionFrom = as.Date(ConsumptionFrom,'%Y-%m-%d'),
ConsumptionTo = as.Date(ConsumptionTo,'%Y-%m-%d'))
temp2$DaysofConsumption = as.numeric(temp2$ConsumptionTo - temp2$ConsumptionFrom)+1
temp2$PerDayConsumption_KVAH = temp2$ISU_Consumption_KVAH/temp2$DaysofConsumption
temp2$PerDayConsumption_KWH = temp2$ISU_Consumption_KWH/temp2$DaysofConsumption
temp2$PerDayConsumption_TOD1 = temp2$Consumption_TOD1/temp2$DaysofConsumption
temp2$PerDayConsumption_TOD2 = temp2$Consumption_TOD2/temp2$DaysofConsumption
temp2$PerDayConsumption_TOD3 = temp2$Consumption_TOD3/temp2$DaysofConsumption
#temp2 = temp2[temp2$ConsumptionFrom >= startdate,]
first = TRUE
for(i in 1:nrow(temp2)){
print(i)
Ndays = temp2$DaysofConsumption[i]
ConsumerNumber = c(rep(temp2$ConsumerNumber[i],Ndays))
ConsumptionDate = c(seq(temp2$ConsumptionFrom[i],temp2$ConsumptionTo[i],"day"))
consumption_KVAH = c(rep(temp2$PerDayConsumption_KVAH[i],Ndays))
consumption_KWH = c(rep(temp2$PerDayConsumption_KWH[i],Ndays))
consumption_TOD1 = c(rep(temp2$PerDayConsumption_TOD1[i],Ndays))
consumption_TOD2 = c(rep(temp2$PerDayConsumption_TOD2[i],Ndays))
consumption_TOD3 = c(rep(temp2$PerDayConsumption_TOD3[i],Ndays))
tempdf = data.frame(ConsumerNumber,ConsumptionDate,consumption_KVAH,consumption_KWH,
consumption_TOD1,consumption_TOD2,consumption_TOD3)
if(first == TRUE){
first = FALSE
DayWiseConsumption = tempdf
}else{
DayWiseConsumption = rbind(DayWiseConsumption,tempdf)
}
}
rm(groupColumns,dataColumns,tempdf,Ndays,ConsumerNumber,ConsumptionDate,consumption_KVAH,
consumption_KWH,consumption_TOD1,consumption_TOD2,consumption_TOD3,first)
return(DayWiseConsumption)
}
checkForNAColumns <- function(df){
named_cols = colSums(is.na(df))/nrow(df)
for(i in 1:length(named_cols)){
if(named_cols[i] != 0){
print(named_cols[i])
}
}
rm(named_cols,i)
}
getEventDurations <- function(df, meterconsumerdf){
df$EVENTDATE = gsub('\\s+','',df$EVENTDATE)
df$EVENTTIME = gsub('\\s+','',df$EVENTTIME)
df = transform(df,
DATETIMESTAMP = strptime(DATETIMESTAMP, "%Y-%m-%d %H:%M:%S"),
EVENTDATE = as.Date(EVENTDATE, "%d-%b-%Y"))
df = merge(df,
meterconsumerdf,
by = "METERNO", all.x = TRUE)
# Compute the suspicious event duration
error_idx = df$EVENTTIME == "00:00AM"
df = df[!error_idx,]
df = df[with(df,
order(df[,"ConsumerNumber"],
df[,"METERNO"],
df[,"CODE"],
df[,"DATETIMESTAMP"])),]
df$EVENT_CLOSE = FALSE
df$DURATION = -1
last_event_code = 0
last_cnumber = 0
last_event_status = -1
last_event_ts = 0
RESET_FLAG = FALSE
for(i in 1:nrow(df)){
print(i)
if((i == 1) |(RESET_FLAG == TRUE)){
# First Event Occured or Reset Flag is set
last_idx = i
last_event_code = df$CODE[i]
last_cnumber = df$ConsumerNumber[i]
last_meternumber = df$METERNO[i]
last_event_status = df$STATUS[i]
last_event_ts = df$DATETIMESTAMP[i]
RESET_FLAG = FALSE
}else{
# After First Event row
current_event_code = df$CODE[i]
current_cnumber = df$ConsumerNumber[i]
current_meternumber = df$METERNO[i]
current_event_status = df$STATUS[i]
current_event_ts = df$DATETIMESTAMP[i]
if(current_cnumber == last_cnumber){
# If event for same consumer, then next check for same meter number
if(current_meternumber == last_meternumber){
# If the next event is from the same meter, then check for event code
if(current_event_code == last_event_code){
# If same event is occured again , check for status code
if(current_event_status != last_event_status){
# If the event status is changed, i.e Occur to Restore / Restore to Occur
if(current_event_status == 1){
# If the previous event is restored, compute the time duration in
# Hours and set Event Close Flag for that event
event_duration = as.numeric(difftime(current_event_ts,
last_event_ts,
units = "hours"))
# Check for debugging
if(event_duration < -2){
print(last_idx)
print(last_event_ts)
print(current_event_ts)
return(df)
}
#####################
df$EVENT_CLOSE[last_idx] = TRUE
df$DURATION[last_idx] = event_duration
df$EVENT_CLOSE[i] = TRUE
df$DURATION[i] = event_duration
# Set Reset Flag ON and jump to next iteration
RESET_FLAG = TRUE
next
# End of Event Status check
}else{
# Occur event received after Restore for same event code
# Then ignore the last Restore and start monitoring current event code
last_event_status = current_event_status
last_event_code = current_event_code
last_event_ts = current_event_ts
last_idx = i
} # End of change in event status check
}else{
# Restore / Occur event are receiving repeatidly , then ignore all except first
# Set the Duration to -2 , to show that the events are repeatitive
df$DURATION[i] = -2
next
}
}else{ # End of event code check
# If the another event occurs for same consumer
# Then update the event monitoring parameters
last_event_code = current_event_code
last_event_status = current_event_status
last_event_ts = current_event_ts
last_idx = i
}
}else{ # End of Meter number check
# If meter number changes for same consumer, then change start
# monitoring the new event
last_meternumber = current_meternumber
last_event_code = current_event_code
last_event_status = current_event_status
last_event_ts = current_event_ts
last_idx = i
}
}else{ # end of consumer number check
# If consumer number changes then start monitoring current event
last_meternumber = current_meternumber
last_cnumber = current_cnumber
last_event_code = current_event_code
last_event_status = current_event_status
last_event_ts = current_event_ts
last_idx = i
}
}
}
return(df)
}
# Compute the monthly recorded peak demand
getMonthlyPeakDemand <- function(df){
# Remove the duplicate entries
#df = unique(df)
# load library plyr
library(plyr)
# Add the duration field to the consumption data
df$Duration = paste(df$ConsumptionFrom,df$ConsumptionTo,sep = " to ")
# Covert all demand into KWH
bhp_idx = df$UOM == "BHP"
kva_idx = df$UOM == "KVA"
kw_idx = df$UOM == "KW"
df$RecordedDemand_KW = 0
df$RecordedDemand_KW[bhp_idx] = 0.745699872 *
df$BillableDemandConsumption[bhp_idx]
df$RecordedDemand_KW[kva_idx] = 0.9 * df$BillableDemandConsumption[kva_idx]
df$RecordedDemand_KW[kw_idx] = df$BillableDemandConsumption[kw_idx]
rm(bhp_idx,kva_idx,kw_idx)
# Group by consumer number and then by duration and compute the sum of
# all the BillableDemandConsumption
library(dplyr)
PeakDemandDF = df %>%
group_by(ConsumerNumber,Duration) %>%
summarise(RecordedDemand_KW = sum(RecordedDemand_KW))
# Now split the duration into startdate and last date
library(stringr)
PeakDemandDF$StartDate = str_split_fixed(PeakDemandDF$Duration," to ",2)[,1]
PeakDemandDF$EndDate = str_split_fixed(PeakDemandDF$Duration," to ",2)[,2]
# Convert the start Date and End date into date format
PeakDemandDF = transform(PeakDemandDF,
StartDate = as.Date(StartDate,'%Y-%m-%d'),
EndDate = as.Date(EndDate,'%Y-%m-%d'))
first = TRUE
library(zoo)
# Now generate new df with monthwise recorded demand
for(i in 1:nrow(PeakDemandDF)){
Month = c(as.yearmon(PeakDemandDF$StartDate[i],PeakDemandDF$EndDate[i],
"month"))
n = length(Month)
ConsumerNumber = c(rep(PeakDemandDF$ConsumerNumber[i],n))
BillableDemand_KW = c(rep(PeakDemandDF$RecordedDemand_KW[i],n))
tempDF = data.frame(ConsumerNumber,Month,BillableDemand_KW)
if(first == TRUE){
MonthlyBilledDemandDF = tempDF
first = FALSE
}else{
MonthlyBilledDemandDF = rbind(MonthlyBilledDemandDF,tempDF)
}
}
# Compute the max recorded demand for a month
MonthlyBilledDemandDF = MonthlyBilledDemandDF %>%
group_by(ConsumerNumber,Month)%>%
summarise(BillableDemand_KW = max(BillableDemand_KW))
MonthlyBilledDemandDF$MonthofConsumption = as.Date(MonthlyBilledDemandDF$Month)
rm(first,i,tempDF,ConsumerNumber,n,BillableDemand_KW,Month)
return(MonthlyBilledDemandDF)
}
getMonthlySanctionedLoad <- function(df){
SanctionedLoadDF = data.frame(0,as.Date('2017-12-31','%Y-%m-%d'),0)
names(SanctionedLoadDF) = c("ConsumerNumber","MonthofConsumption","Load")
idx = df$ValidToDate == as.Date('2050-12-31','%Y-%m-%d')
df[idx,"ValidToDate"] = as.Date('2020-06-01','%Y-%m-%d')
for(i in 1:nrow(df)){
date_seq = seq(as.Date(as.yearmon(df$ValidFromDate[i])),
as.Date(as.yearmon(df$ValidToDate[i])),by="month")
consumer_no = rep(df$ConsumerNumber[i],length(date_seq))
load = rep(df$SanctionedLoad_KW[i],length(date_seq))
temp = data.frame(consumer_no,date_seq,load)
names(temp) = c("ConsumerNumber","MonthofConsumption","Load")
SanctionedLoadDF = rbind(SanctionedLoadDF,
temp)
}
SanctionedLoadDF = SanctionedLoadDF[-c(1),]
row_idx = SanctionedLoadDF$MonthofConsumption >= as.Date('2015-01-01','%Y-%m-%d') &
SanctionedLoadDF$MonthofConsumption <= as.Date('2017-06-01','%Y-%m-%d')
SanctionedLoadDF = SanctionedLoadDF[row_idx,]
SanctionedLoadDF = SanctionedLoadDF %>%
group_by(ConsumerNumber,MonthofConsumption) %>%
summarise(SanctionedLoadinKW = max(Load))
rm(temp,i,row_idx,date_seq,consumer_no,load)
return(SanctionedLoadDF)
}
computeLF <- function(df){
# load lubridate for computing number of days in a month
library(lubridate)
df$NumberofDays = days_in_month(df$MonthofConsumption)
# Compute the load factor
# Load Factor = Total Consumption in kWh/(Number of Days * 24 * Peak Recorded Demand in KW)
}
MeterConsumerNumberDF = read.csv("Data//PROCESSED//MeterMasterDF.csv", header = TRUE, stringsAsFactors = FALSE)
MeterConsumerNumberDF = MeterConsumerNumberDF[,c("ConsumerNumber","METERNO")]
#source("DataPreparation.R")
MonthlyConsumptionDF = getPerDayConsumption(read.csv("Data//PROCESSED//ConsumptionDF.csv", header = TRUE, stringsAsFactors = FALSE))
MonthlyConsumptionDF = MonthlyConsumptionDF[,c("ConsumerNumber","ConsumptionDate",
"consumption_KVAH")]
library(dplyr)
library(zoo)
MonthlyConsumptionDF$MonthofConsumption = as.Date(as.yearmon(MonthlyConsumptionDF$ConsumptionDate))
MonthlyConsumptionDF = MonthlyConsumptionDF %>%
dplyr::group_by(ConsumerNumber,MonthofConsumption) %>%
dplyr::summarise(consumption_KVAH = sum(consumption_KVAH))
#source("DataPreparation.R")
SuspiciousEventDuration = getEventDurations(read.csv("Data//PROCESSED//SuspiciousEventDF.csv", header = TRUE, stringsAsFactors = FALSE),
MeterConsumerNumberDF)
write.csv(MonthlyConsumptionDF, "Data//PROCESSED//MonthlyConsumptionStandardisedDF.csv", row.names = FALSE)
write.csv(SuspiciousEventDuration, "Data//PROCESSED//SuspiciousEventDuration.csv", row.names = FALSE)
setwd("C:/TCGDIGITAL/FINAL_DELIVERABLE")
getSuspiciousEventCounts<- function(df){
SuspiciousEventData = transform(df, EVENTDATE = as.Date(EVENTDATE,"%Y-%m-%d"))
# label the events
SuspiciousEventData$EVENT_LABEL = ""
cwv_idx = (SuspiciousEventData$CODE == 1)|(SuspiciousEventData$CODE == 2) |
(SuspiciousEventData$CODE == 3)
cts_idx = (SuspiciousEventData$CODE == 19)
ctb_idx = (SuspiciousEventData$CODE == 1201)
cto_idx = (SuspiciousEventData$CODE == 23)| (SuspiciousEventData$CODE == 24) |
(SuspiciousEventData$CODE == 25) | (SuspiciousEventData$CODE == 26)
cm_idx = (SuspiciousEventData$CODE == 30) | (SuspiciousEventData$CODE == 31) |
(SuspiciousEventData$CODE == 32)
vimb_idx = (SuspiciousEventData$CODE == 14)
ipa_idx = (SuspiciousEventData$CODE == 18) | (SuspiciousEventData$CODE == 66)
nd_idx = (SuspiciousEventData$CODE == 28)
lon_idx = (SuspiciousEventData$CODE == 1208)
mt_idx = (SuspiciousEventData$CODE == 27)
co_idx = (SuspiciousEventData$CODE == 60)
# Add labels
SuspiciousEventData[cwv_idx,'EVENT_LABEL'] = "CURRENT_WITHOUT_VOLTAGE"
SuspiciousEventData[cts_idx,'EVENT_LABEL'] = "CURRENT_TERMINAL_SHORT"
SuspiciousEventData[ctb_idx,'EVENT_LABEL'] = "CURRENT_TERMINAL_BYPASS"
SuspiciousEventData[cto_idx,'EVENT_LABEL'] = "CURRENT_TERMINAL_OPEN"
SuspiciousEventData[cm_idx,'EVENT_LABEL'] = "CURRENT_MISSING"
SuspiciousEventData[vimb_idx,'EVENT_LABEL'] = "VOLTAGE_IMBALANCE"
SuspiciousEventData[ipa_idx,'EVENT_LABEL'] = "INVALID_VOLTAGE"
SuspiciousEventData[nd_idx,'EVENT_LABEL'] = "NEUTRAL_DISTURBANCE"
SuspiciousEventData[lon_idx,'EVENT_LABEL'] = "LOSS_OF_NEUTRAL"
SuspiciousEventData[mt_idx,'EVENT_LABEL'] = "MAGNET_TAMPER"
SuspiciousEventData[co_idx,'EVENT_LABEL'] = "COVER_OPEN"
rm(cwv_idx,cts_idx,ctb_idx,cto_idx,cm_idx,vimb_idx,ipa_idx,nd_idx,lon_idx,mt_idx,co_idx)
SuspiciousEventData = SuspiciousEventData[(SuspiciousEventData$EVENT_CLOSE == TRUE)&
(SuspiciousEventData$DURATION > -1)&
(SuspiciousEventData$STATUS == 0),]
library(dplyr)
library(tidyr)
EventCounts = SuspiciousEventData %>%
dplyr::group_by(ConsumerNumber,EVENT_LABEL) %>%
dplyr::summarise(Count = n()) %>%
tidyr::spread(EVENT_LABEL,Count)
EventCounts[is.na(EventCounts)] = 0
return(EventCounts)
}
#===================After preprocessing===================
MonthlyDataDF<-read.csv("Data//PROCESSED//MonthlyConsumptionData.csv", header = TRUE, stringsAsFactors = FALSE)
EventDF<-read.csv("Data//PROCESSED//SuspiciousEventDuration.csv", header = TRUE, stringsAsFactors = FALSE)
MeterConsumerNumberDF = read.csv("Data//PROCESSED//MeterMasterDF.csv", header = TRUE, stringsAsFactors = FALSE)
MeterConsumerNumberDF = MeterConsumerNumberDF[,c("ConsumerNumber","METERNO")]
source("Method2.R")
Risk2 = Method2("Data//PROCESSED//MeterMasterDF.csv",
"Data//PROCESSED//MonthlyConsumptionData.csv",
"Data//PROCESSED//SuspiciousEventDuration.csv")
source("Method3.R")
Risk3 = Method3(MonthlyDataDF,'01-06-2017',EventDF)
source("Method5.R")
Risk5 = Method5(MonthlyDataDF)
CustomerMaster<- read.csv("Data//PROCESSED//CustomerMasterDF.csv",header = TRUE, stringsAsFactors = FALSE)
CustomerMaster = merge(CustomerMaster,
Risk2,
by = "ConsumerNumber",
all.x = TRUE)
CustomerMaster = merge(CustomerMaster,
Risk3,
by = "ConsumerNumber",
all.x = TRUE)
CustomerMaster = merge(CustomerMaster,
Risk5,
by = "ConsumerNumber",
all.x = TRUE)
# Fill the NA values with Not Recommended
CustomerMaster[is.na(CustomerMaster$Risk2),"Risk2"] = "NoRecommendation"
CustomerMaster[is.na(CustomerMaster$Risk3),"Risk3"] = "NoRecommendation"
CustomerMaster[is.na(CustomerMaster$Risk5),"Risk5"] = "NoRecommendation"
# Compute the finale Risk based on 5 risk categories
# Load final Risk mapping files
#FinalRisk
# Load Geo-tags
GeoCodeDF = read.csv("Data//RAW//Customer_Geocoordinates.csv", header = TRUE,
stringsAsFactors = FALSE)
CustomerMaster = merge(CustomerMaster,
GeoCodeDF[,c("ConsumerNumber","Lat","Long")],
by="ConsumerNumber",
all.x = TRUE)
Rules = read.csv("Data//PROCESSED//Rules.csv", header = TRUE,
stringsAsFactors = FALSE)
CustomerMaster = merge(CustomerMaster,
Rules,
by = c("Risk2","Risk3","Risk5"),
all.x = TRUE)
#
# # Load the feedback file
# # Feedback Codes
# # 0. Not inspected
# # 1. Not Flag for next 6 months
# # 2. Flase positive
# # 3. Continue to flag
# # 4. Action needed from NPCL
# # 5. TD Done. Donot Flag in future.
FeedbackDF = read.csv("Data//PROCESSED//feedback.csv", header = TRUE,
stringsAsFactors = FALSE)
FeedbackDF = transform(FeedbackDF,
InspectionDate = as.Date(InspectionDate,'%d-%m-%Y'))
TodayDate = as.Date(format(Sys.Date(),'%d-%m-%Y'),'%d-%m-%Y')
#
# # Out of the final recommended from high cases, remove the cases other than 0
#
CustomerMaster = merge(CustomerMaster,
FeedbackDF,
by = "ConsumerNumber",
all.x = TRUE)
MonthlyDataDF = transform(MonthlyDataDF, MoveInDate = as.Date(MoveInDate, '%Y-%m-%d'),
MonthofConsumption = as.Date(MonthofConsumption, '%Y-%m-%d'))
library(dplyr)
library(tidyr)
ConsumptionStats = MonthlyDataDF %>%
dplyr::mutate(Year = year(MonthofConsumption)) %>%
dplyr::filter(Year >= 2015) %>%
dplyr::group_by(ConsumerNumber,Year)%>%
dplyr::summarise(Avg = mean(Consumption_kWh)) %>%
tidyr::spread(Year,Avg)
ConsumptionStats[is.na(ConsumptionStats)] = 0
names(ConsumptionStats) = c("ConsumerNumber","Average_2015","Average_2016","Average_2017")
ZeroConsumption = MonthlyDataDF %>%
dplyr::group_by(ConsumerNumber)%>%
dplyr::summarise(ZeroConsumptionMonths = sum(Consumption_kWh == 0))
CustomerMaster = merge(CustomerMaster,
ConsumptionStats,
by="ConsumerNumber",
all.x = TRUE)
CustomerMaster = merge(CustomerMaster,
ZeroConsumption,
by="ConsumerNumber",
all.x = TRUE)
# Get Event Counts
EventCountsDF = getSuspiciousEventCounts(EventDF)
n1 = ncol(CustomerMaster)
CustomerMaster = merge(CustomerMaster,
EventCountsDF,
by = "ConsumerNumber",
all.x = TRUE)
n2 = ncol(CustomerMaster)
events = CustomerMaster[,c(seq(n1+1,n2,1))]
events[is.na(events)] = 0
CustomerMaster[,c(seq(n1+1,n2,1))] = events
rm(n1,n2,events)
# Only Recommend which are yet to be inspected or it's threshold crosses the time of 6 months
idx = (CustomerMaster$FinalRisk == "High") &
((CustomerMaster$FeedbackCode == 0) |
((CustomerMaster$FeedbackCode == 1) & as.numeric(TodayDate - CustomerMaster$InspectionDate)>180))
HighRiskCustomers = CustomerMaster[idx,]
rm(idx)
# Convert
# Sort the high risk consumers by numbers of zero consumption days
HighRiskCustomers = HighRiskCustomers[ order(-HighRiskCustomers[,"ZeroConsumptionMonths"]), ]
cols = c("ConsumerNumber","Name","StreetType","ConsumerType","RateCategory",
"Load","LoadUoM","MoveInDate","Risk2","Risk3","Risk5",
"FinalRisk")
FinalOutput = CustomerMaster[,c("ConsumerNumber","Name","StreetType","ConsumerType","RateCategory",
"Load","LoadUoM","MoveInDate","Average_2015","Average_2016","Average_2017",
"CURRENT_MISSING","CURRENT_TERMINAL_BYPASS","CURRENT_TERMINAL_OPEN",
"CURRENT_TERMINAL_SHORT","CURRENT_WITHOUT_VOLTAGE","INVALID_VOLTAGE",
"LOSS_OF_NEUTRAL","MAGNET_TAMPER","NEUTRAL_DISTURBANCE","VOLTAGE_IMBALANCE",
"ZeroConsumptionMonths","Risk2","Risk3","Risk5","FinalRisk","InspectionDate",
"FeedbackComment")]
require(XLConnect)
wb = loadWorkbook("Data\\RAW\\CustomerMasterData.xlsx")
CustomerInfoDf = readWorksheet(wb, sheet = "Sheet1", header = TRUE)
# Get the top list of n customers for recommendation
n = 50
cols = c("Consumer.No.","Name","Care.Of","Rate.Category","Street","House.No.",
"House.No.","Tel.No.","Mobile.No")
CustomerInfoDf = CustomerInfoDf[,cols]
names(CustomerInfoDf)[names(CustomerInfoDf) == 'Consumer.No.'] <- 'ConsumerNumber'
HighRiskCustomers = HighRiskCustomers[,c("ConsumerNumber","ConsumerType","StreetType","Lat","Long")]
# Select the high risk customers
CustomerInfoDf = merge(CustomerInfoDf,
HighRiskCustomers,
by=c("ConsumerNumber"))
cols = c("ConsumerNumber","Name","Care.Of","Rate.Category","ConsumerType","StreetType",
"Street","House.No.","House.No.","Tel.No.","Mobile.No")
RecommendationFile = CustomerInfoDf[,cols]
write.csv(FinalOutput,"Data\\OUTPUT\\AllConsumerRisk.csv",row.names = FALSE)
write.csv(RecommendationFile,"Data\\OUTPUT\\RecommendationFile.csv", row.names = FALSE)
# First take the top columns with RU
# CustomerMaster = CustomerMaster[,cols]
#
# # Take only the High RIsk Customers
# RecommendFile = CustomerMaster[CustomerMaster$FinalRisk=="High",]
# RecommendFile = RecommendFile[!is.na(RecommendFile$FinalRisk),]
# Recommend in order
